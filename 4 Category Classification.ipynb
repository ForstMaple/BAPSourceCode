{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author:     Maple FENG  \n",
    "Data:       2021-10-19  \n",
    "Document:   tfidf.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from langdetect import detect\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2080, 13)\n",
      "(890, 13)\n"
     ]
    }
   ],
   "source": [
    "train_all = pd.read_csv('train1020.csv')\n",
    "test_all = pd.read_csv('test1020.csv')\n",
    "print(train_all.shape)\n",
    "print(test_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2029, 13)\n",
      "(877, 13)\n"
     ]
    }
   ],
   "source": [
    "train_filtered = train_all[~train_all['description'].isna()]\n",
    "test_filtered = test_all[~test_all['description'].isna()]\n",
    "print(train_filtered.shape)\n",
    "print(test_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1831, 13)\n",
      "(803, 13)\n"
     ]
    }
   ],
   "source": [
    "train_en = train_filtered[(train_filtered['description'].apply(lambda x: detect(x)) == 'en') & \n",
    "                          (train_filtered['title'].apply(lambda x: detect(x)) == 'en')]\n",
    "test_en = test_filtered[(test_filtered['description'].apply(lambda x: detect(x)) == 'en') & \n",
    "                        (test_filtered['title'].apply(lambda x: detect(x)) == 'en')]\n",
    "print(train_en.shape)\n",
    "print(test_en.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_en['title'] + ' ' + train_en['description']\n",
    "test = test_en['title'] + ' ' + test_en['description']\n",
    "Y_train = train_en['category']\n",
    "Y_test = test_en['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "\n",
      "Business                            434\n",
      "Computer Science                    259\n",
      "Health                              241\n",
      "Data Science                        201\n",
      "Social Sciences                     173\n",
      "Physical Science and Engineering    171\n",
      "Arts and Humanities                 151\n",
      "Information Technology               81\n",
      "Language Learning                    53\n",
      "Personal Development                 45\n",
      "Math and Logic                       22\n",
      "Name: category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Training Set\\n')\n",
    "print(Y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set\n",
      "\n",
      "Business                            184\n",
      "Health                              115\n",
      "Data Science                         98\n",
      "Computer Science                     95\n",
      "Physical Science and Engineering     92\n",
      "Social Sciences                      64\n",
      "Arts and Humanities                  54\n",
      "Language Learning                    36\n",
      "Information Technology               34\n",
      "Personal Development                 23\n",
      "Math and Logic                        8\n",
      "Name: category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Test Set\\n')\n",
    "print(Y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystopwords = stopwords.words('english') + ['\\'s', 'university', 'universities', 'student', 'students', 'mooc',\n",
    "                                            'one', 'two', 'three', 'introduction', 'use', 'don\\'t', 'doesn\\'t', '\\'m',\n",
    "                                            '--', '...', '10,000', '16,000,000,000', '1990s', '2030.', '20th', '21st', \n",
    "                                            '2d', '360‚ñ¢', '3d', '4-week', '500,000', '8.', '``', '\\'\\'', '‚äì', '‚äî','‚äù',\n",
    "                                            '\\'ll', 'also', 'would', 'we\\'ll', 'via', 'upon', ]\n",
    "garble = re.compile(r'‚äô')\n",
    "punctuations = string.punctuation + \"’“”\" \n",
    "steammer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower().strip())\n",
    "    tokens = [garble.sub('\\'', token) for token in tokens]\n",
    "    tokens = [token for token in tokens if token not in mystopwords]\n",
    "    tokens = [token for token in tokens if token not in punctuations]\n",
    "    tokens = [token for token in tokens if not token.isnumeric()]\n",
    "    tokens = [token for token in tokens if len(token) > 1]\n",
    "    # tokens = [lemmatizer.lemmatize(token).strip() for token in tokens]\n",
    "    tokens = [steammer.stem(token).strip() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=preprocess, decode_error='ignore', max_df=0.7, min_df=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1831x847 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 44588 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = vectorizer.fit_transform(train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.15075365,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abil', 'abl', 'academ', 'acceler', 'access', 'accord', 'account',\n",
       "       'achiev', 'acquir', 'across', 'act', 'action', 'activ', 'actual',\n",
       "       'ad', 'adapt', 'addit', 'address', 'administr', 'adopt', 'advanc',\n",
       "       'affect', 'age', 'ai', 'aim', 'algorithm', 'allow', 'almost',\n",
       "       'along', 'alreadi', 'altern', 'alway', 'american', 'among',\n",
       "       'analys', 'analysi', 'analyt', 'analyz', 'anim', 'anoth', 'answer',\n",
       "       'anyon', 'api', 'app', 'appli', 'applic', 'appreci', 'approach',\n",
       "       'appropri', 'architectur', 'area', 'around', 'art', 'artifici',\n",
       "       'artist', 'ask', 'aspect', 'assess', 'asset', 'assign', 'associ',\n",
       "       'assum', 'attent', 'audienc', 'author', 'autom', 'avail', 'avoid',\n",
       "       'aw', 'awar', 'background', 'balanc', 'base', 'basi', 'basic',\n",
       "       'becom', 'begin', 'behavior', 'behind', 'benefit', 'best',\n",
       "       'better', 'beyond', 'big', 'bioinformat', 'biolog', 'blockchain',\n",
       "       'board', 'bodi', 'book', 'boulder', 'brand', 'bring', 'broad',\n",
       "       'build', 'busi', 'call', 'capabl', 'capit', 'capston', 'care',\n",
       "       'career', 'carri', 'case', 'caus', 'center', 'central', 'centuri',\n",
       "       'certain', 'certif', 'chain', 'challeng', 'chanc', 'chang',\n",
       "       'characterist', 'children', 'china', 'chines', 'choic', 'choos',\n",
       "       'class', 'classic', 'classroom', 'clear', 'client', 'climat',\n",
       "       'clinic', 'cloud', 'code', 'collabor', 'colleagu', 'collect',\n",
       "       'combin', 'come', 'common', 'communic', 'communiti', 'compani',\n",
       "       'compar', 'compet', 'competit', 'complet', 'complex', 'compon',\n",
       "       'comprehens', 'comput', 'concept', 'conceptu', 'concern',\n",
       "       'conclud', 'condit', 'conduct', 'confid', 'conflict', 'connect',\n",
       "       'consequ', 'consid', 'consider', 'consist', 'construct', 'consum',\n",
       "       'contain', 'contemporari', 'content', 'context', 'continu',\n",
       "       'contribut', 'control', 'convers', 'core', 'corpor', 'correct',\n",
       "       'cost', 'could', 'countri', 'coursera', 'cover', 'craft', 'creat',\n",
       "       'creation', 'creativ', 'credit', 'critic', 'crucial', 'cu',\n",
       "       'cultur', 'current', 'custom', 'cybersecur', 'daili', 'data',\n",
       "       'data-driven', 'dataset', 'day', 'deal', 'decad', 'decid', 'decis',\n",
       "       'decision-mak', 'deep', 'deeper', 'defin', 'degre', 'deliv',\n",
       "       'deliveri', 'demand', 'demonstr', 'depend', 'deploy', 'describ',\n",
       "       'descript', 'design', 'detail', 'determin', 'develop', 'devic',\n",
       "       'differ', 'differenti', 'difficult', 'digit', 'direct',\n",
       "       'disciplin', 'discov', 'discoveri', 'discuss', 'diseas',\n",
       "       'distribut', 'dive', 'divers', 'document', 'domain', 'done',\n",
       "       'draw', 'drive', 'dynam', 'earli', 'earth', 'easi', 'ecea',\n",
       "       'econom', 'economi', 'educ', 'effect', 'effici', 'effort',\n",
       "       'electr', 'element', 'embed', 'emerg', 'emot', 'emphasi', 'employ',\n",
       "       'employe', 'empow', 'enabl', 'encount', 'encourag', 'end',\n",
       "       'energi', 'engag', 'engin', 'english', 'enhanc', 'enough', 'ensur',\n",
       "       'enterpris', 'entrepreneur', 'entrepreneurship', 'environ',\n",
       "       'environment', 'epidemiolog', 'equip', 'error', 'especi',\n",
       "       'essenti', 'establish', 'estim', 'ethic', 'evalu', 'even', 'event',\n",
       "       'ever', 'everi', 'everyday', 'everyon', 'everyth', 'evid',\n",
       "       'evolut', 'evolv', 'exam', 'examin', 'exampl', 'excel', 'excit',\n",
       "       'execut', 'exercis', 'exist', 'expand', 'expect', 'experi',\n",
       "       'experienc', 'expert', 'explain', 'explor', 'express', 'extern',\n",
       "       'extract', 'face', 'facilit', 'fact', 'factor', 'faculti',\n",
       "       'famili', 'familiar', 'featur', 'feedback', 'feel', 'field',\n",
       "       'file', 'final', 'financ', 'financi', 'find', 'firm', 'first',\n",
       "       'five', 'flow', 'focus', 'follow', 'forc', 'form', 'format',\n",
       "       'formul', 'forward', 'foundat', 'four', 'fourth', 'framework',\n",
       "       'free', 'friend', 'full', 'fulli', 'function', 'fund', 'fundament',\n",
       "       'futur', 'gain', 'game', 'general', 'generat', 'genom', 'get',\n",
       "       'give', 'given', 'global', 'globe', 'go', 'goal', 'good', 'googl',\n",
       "       'govern', 'grammar', 'graphic', 'great', 'group', 'grow', 'growth',\n",
       "       'guid', 'hand', 'handl', 'hands-on', 'happen', 'hardwar', 'health',\n",
       "       'healthcar', 'hear', 'help', 'high', 'highlight', 'histor',\n",
       "       'histori', 'home', 'hope', 'howev', 'https', 'human', 'ibm',\n",
       "       'idea', 'ideal', 'ident', 'identifi', 'ii', 'illustr', 'imag',\n",
       "       'impact', 'implement', 'implic', 'import', 'improv', 'includ',\n",
       "       'inclus', 'incom', 'incorpor', 'increas', 'individu', 'industri',\n",
       "       'influenc', 'inform', 'infrastructur', 'initi', 'innov', 'input',\n",
       "       'insight', 'institut', 'instruct', 'integr', 'intellectu',\n",
       "       'intellig', 'intend', 'interact', 'interest', 'interfac', 'intern',\n",
       "       'internet', 'interpret', 'intervent', 'interview', 'introduc',\n",
       "       'introductori', 'invest', 'investig', 'investor', 'involv', 'issu',\n",
       "       'java', 'job', 'join', 'journey', 'keep', 'key', 'kind', 'know',\n",
       "       'knowledg', 'known', 'lab', 'landscap', 'languag', 'larg',\n",
       "       'larger', 'last', 'latest', 'law', 'lead', 'leader', 'leadership',\n",
       "       'learn', 'learner', 'lectur', 'led', 'legal', 'lesson', 'let',\n",
       "       'level', 'leverag', 'librari', 'life', 'like', 'limit', 'line',\n",
       "       'linear', 'link', 'listen', 'literatur', 'littl', 'live', 'local',\n",
       "       'long', 'look', 'lot', 'machin', 'made', 'main', 'maintain',\n",
       "       'major', 'make', 'manag', 'mani', 'manipul', 'manufactur', 'map',\n",
       "       'market', 'master', 'materi', 'mathemat', 'matter', 'maxim', 'may',\n",
       "       'mean', 'meaning', 'measur', 'mechan', 'media', 'medic', 'medicin',\n",
       "       'meet', 'member', 'memori', 'mental', 'method', 'methodolog',\n",
       "       'might', 'million', 'mind', 'mobil', 'mode', 'model', 'modern',\n",
       "       'modul', 'money', 'motion', 'move', 'movement', 'much', 'multipl',\n",
       "       'music', 'must', \"n't\", 'nation', 'natur', 'navig', 'necessari',\n",
       "       'need', 'negoti', 'network', 'new', 'next', 'novel', 'number',\n",
       "       'numer', 'object', 'obtain', 'offer', 'often', 'onlin', 'open',\n",
       "       'oper', 'opportun', 'optim', 'option', 'order', 'organ', 'organis',\n",
       "       'organiz', 'origin', 'other', 'outcom', 'overal', 'overview',\n",
       "       'packag', 'paradigm', 'part', 'particip', 'particular', 'past',\n",
       "       'path', 'patient', 'pattern', 'peer', 'peopl', 'perform', 'period',\n",
       "       'person', 'perspect', 'phase', 'philosophi', 'phone', 'physic',\n",
       "       'place', 'plan', 'platform', 'play', 'pleas', 'point', 'polici',\n",
       "       'polit', 'popul', 'popular', 'portfolio', 'posit', 'possibl',\n",
       "       'potenti', 'power', 'practic', 'predict', 'prepar', 'present',\n",
       "       'prevent', 'previous', 'price', 'primari', 'principl', 'prior',\n",
       "       'privat', 'probabl', 'problem', 'process', 'produc', 'product',\n",
       "       'profession', 'professor', 'profit', 'program', 'programm',\n",
       "       'progress', 'project', 'promot', 'properti', 'propos', 'protect',\n",
       "       'provid', 'psycholog', 'public', 'purpos', 'put', 'python',\n",
       "       'qualiti', 'quantit', 'question', 'quick', 'quizz', 'rais', 'rang',\n",
       "       'rapid', 'rate', 'reach', 'read', 'readi', 'real', 'real-world',\n",
       "       'realiti', 'realiz', 'realli', 'reason', 'receiv', 'recent',\n",
       "       'recogn', 'recommend', 'record', 'reduc', 'refer', 'reflect',\n",
       "       'regard', 'regress', 'regul', 'relat', 'relationship', 'relev',\n",
       "       'religion', 'remain', 'report', 'repres', 'requir', 'research',\n",
       "       'resourc', 'respect', 'respons', 'result', 'return', 'review',\n",
       "       'revolut', 'right', 'rise', 'risk', 'robot', 'role', 'run',\n",
       "       'safeti', 'sale', 'sampl', 'scalabl', 'scale', 'scenario',\n",
       "       'school', 'scienc', 'scientif', 'scientist', 'search', 'second',\n",
       "       'sector', 'secur', 'see', 'seek', 'seem', 'select', 'sens',\n",
       "       'sensor', 'sequenc', 'seri', 'serv', 'server', 'servic', 'session',\n",
       "       'set', 'sever', 'shape', 'share', 'shift', 'short', 'show',\n",
       "       'signific', 'similar', 'simpl', 'simul', 'sinc', 'singl', 'site',\n",
       "       'situat', 'six', 'skill', 'small', 'smart', 'social', 'societi',\n",
       "       'softwar', 'solid', 'solut', 'solv', 'sometim', 'sound', 'sourc',\n",
       "       'space', 'span', 'speak', 'special', 'specif', 'stakehold',\n",
       "       'standard', 'start', 'startup', 'state', 'statement', 'statist',\n",
       "       'step', 'still', 'storag', 'stori', 'strateg', 'strategi',\n",
       "       'strengthen', 'strong', 'structur', 'studi', 'style', 'subject',\n",
       "       'success', 'suppli', 'support', 'survey', 'surviv', 'sustain',\n",
       "       'system', 'take', 'taken', 'talk', 'task', 'taught', 'teach',\n",
       "       'teacher', 'team', 'technic', 'techniqu', 'technolog', 'tell',\n",
       "       'term', 'test', 'text', 'theoret', 'theori', 'thing', 'think',\n",
       "       'third', 'thought', 'throughout', 'time', 'today', 'togeth',\n",
       "       'tool', 'topic', 'toward', 'trade', 'tradit', 'train', 'transact',\n",
       "       'transform', 'translat', 'treatment', 'trend', 'tri', 'turn',\n",
       "       'type', 'typic', 'u.s.', 'ultim', 'under', 'understand', 'uniqu',\n",
       "       'unit', 'univers', 'us', 'use', 'user', 'util', 'valid', 'valu',\n",
       "       'valuabl', 'variabl', 'varieti', 'various', 'ventur', 'version',\n",
       "       'video', 'view', 'virtual', 'vision', 'visual', 'want', 'watch',\n",
       "       'way', 'web', 'websit', 'week', 'welcom', 'well', 'whether',\n",
       "       'wide', 'within', 'without', 'women', 'wonder', 'word', 'work',\n",
       "       'workplac', 'world', 'write', 'written', 'year', 'yet'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<803x847 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 19593 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6537982565379825\n",
      "\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "             Arts and Humanities       0.56      0.75      0.64        40\n",
      "                        Business       0.96      0.60      0.74       293\n",
      "                Computer Science       0.80      0.50      0.62       151\n",
      "                    Data Science       0.71      0.72      0.72        97\n",
      "                          Health       0.71      0.73      0.72       113\n",
      "          Information Technology       0.03      0.50      0.06         2\n",
      "               Language Learning       0.36      1.00      0.53        13\n",
      "                  Math and Logic       0.00      0.00      0.00         0\n",
      "            Personal Development       0.00      0.00      0.00         0\n",
      "Physical Science and Engineering       0.49      0.87      0.62        52\n",
      "                 Social Sciences       0.48      0.74      0.58        42\n",
      "\n",
      "                        accuracy                           0.65       803\n",
      "                       macro avg       0.46      0.58      0.48       803\n",
      "                    weighted avg       0.78      0.65      0.69       803\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "print(f'Accuracy: {accuracy_score(Y_pred, Y_test)}\\n')\n",
    "print(classification_report(Y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7023661270236613\n",
      "\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "             Arts and Humanities       0.72      0.64      0.68        61\n",
      "                        Business       0.90      0.70      0.79       236\n",
      "                Computer Science       0.78      0.69      0.73       108\n",
      "                    Data Science       0.77      0.69      0.72       109\n",
      "                          Health       0.73      0.71      0.72       119\n",
      "          Information Technology       0.38      0.65      0.48        20\n",
      "               Language Learning       0.72      0.96      0.83        27\n",
      "                  Math and Logic       0.25      0.50      0.33         4\n",
      "            Personal Development       0.00      0.00      0.00         1\n",
      "Physical Science and Engineering       0.59      0.79      0.68        68\n",
      "                 Social Sciences       0.48      0.62      0.54        50\n",
      "\n",
      "                        accuracy                           0.70       803\n",
      "                       macro avg       0.57      0.63      0.59       803\n",
      "                    weighted avg       0.75      0.70      0.72       803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=80, tol=None)\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "print(f'Accuracy: {accuracy_score(Y_pred, Y_test)}\\n')\n",
    "print(classification_report(Y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6650062266500623\n",
      "\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "             Arts and Humanities       0.67      0.61      0.64        59\n",
      "                        Business       0.80      0.71      0.75       207\n",
      "                Computer Science       0.74      0.65      0.69       107\n",
      "                    Data Science       0.67      0.69      0.68        95\n",
      "                          Health       0.70      0.68      0.69       117\n",
      "          Information Technology       0.56      0.58      0.57        33\n",
      "               Language Learning       0.72      1.00      0.84        26\n",
      "                  Math and Logic       0.25      0.67      0.36         3\n",
      "            Personal Development       0.04      0.11      0.06         9\n",
      "Physical Science and Engineering       0.53      0.60      0.57        81\n",
      "                 Social Sciences       0.59      0.58      0.58        66\n",
      "\n",
      "                        accuracy                           0.67       803\n",
      "                       macro avg       0.57      0.63      0.59       803\n",
      "                    weighted avg       0.68      0.67      0.67       803\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=1e5)\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "print(f'Accuracy: {accuracy_score(Y_pred, Y_test)}\\n')\n",
    "print(classification_report(Y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.684931506849315\n",
      "\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "             Arts and Humanities       0.70      0.72      0.71        53\n",
      "                        Business       0.91      0.65      0.76       255\n",
      "                Computer Science       0.73      0.61      0.66       114\n",
      "                    Data Science       0.78      0.69      0.73       110\n",
      "                          Health       0.75      0.70      0.73       122\n",
      "          Information Technology       0.38      0.72      0.50        18\n",
      "               Language Learning       0.69      0.93      0.79        27\n",
      "                  Math and Logic       0.25      0.67      0.36         3\n",
      "            Personal Development       0.00      0.00      0.00         0\n",
      "Physical Science and Engineering       0.48      0.77      0.59        57\n",
      "                 Social Sciences       0.47      0.68      0.56        44\n",
      "\n",
      "                        accuracy                           0.68       803\n",
      "                       macro avg       0.56      0.65      0.58       803\n",
      "                    weighted avg       0.75      0.68      0.70       803\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, max_depth=70, random_state=1)\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "print(f'Accuracy: {accuracy_score(Y_pred, Y_test)}\\n')\n",
    "print(classification_report(Y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
